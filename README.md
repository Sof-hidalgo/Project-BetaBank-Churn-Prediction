# Project-BetaBank-Churn-Prediction

#  Modelo para Identificar Clientes en Riesgo de Churn - Beta Bank

##  Descripci贸n:
El proyecto busca desarrollar un modelo de machine learning que prediga qu茅 clientes de Beta Bank podr铆an abandonar el banco. Se trabaj贸 con datos hist贸ricos de clientes, incluyendo informaci贸n demogr谩fica, comportamiento financiero y nivel de interacci贸n con el banco.

##  Objetivo:
Crear un modelo predictivo efectivo que permita identificar clientes en riesgo de churn, optimizando la retenci贸n y reduciendo costos de adquisici贸n de nuevos clientes.

### Descripci贸n de los datos
Puedes encontrar los datos en el archivo Churn.csv.

### Caracter铆sticas

- RowNumber: 铆ndice de cadena de datos
- CustomerId: identificador de cliente 煤nico
- Surname: apellido
- CreditScore: valor de cr茅dito
- Geography: pa铆s de residencia
- Gender: sexo
- Age: edad
- Tenure: per铆odo durante el cual ha madurado el dep贸sito a plazo fijo de un cliente (a帽os)
- Balance: saldo de la cuenta
- NumOfProducts: n煤mero de productos bancarios utilizados por el cliente
- HasCrCard: el cliente tiene una tarjeta de cr茅dito (1 - s铆; 0 - no)
- IsActiveMember: actividad del cliente (1 - s铆; 0 - no)
- EstimatedSalary: salario estimado
- Objetivo: Exited: El cliente se ha ido (1 - s铆; 0 - no)

### Pasos del proyecto
- Descargar y preparar los datos.  Explicar el procedimiento.
- Examinar el equilibrio de clases. Entrenar el modelo sin tener en cuenta el desequilibrio. Describir brevemente los hallazgos.
- Mejorar la calidad del modelo. Utilizar al menos dos enfoques para corregir el desequilibrio de clases. Utilizar conjuntos de entrenamiento y validaci贸n para encontrar el mejor modelo y el mejor conjunto de par谩metros. Entrenar diferentes modelos en los conjuntos de entrenamiento y validaci贸n. Encontrar el mejor. Describir brevemente tus hallazgos.
- Realizar la prueba final.

[Igualmente, en el archivo .ipynb se dejar谩n comentarios m谩s espec铆ficos de cada paso.]

##  Conclusiones Finales:
- Mejor Modelo: Random Forest con sobremuestreo obtuvo un F1-score de 0.639 y un AUC-ROC de 0.868, lo que demuestra una alta capacidad de clasificaci贸n.
- Impacto del Balanceo de Clases:
  - Sin balanceo, el F1-score m谩ximo fue 0.6425.
  - Con sobremuestreo, se mantuvo en 0.639, mostrando que es una t茅cnica efectiva para mejorar el equilibrio sin perder precisi贸n.
  - El submuestreo, en cambio, redujo el F1-score a 0.536, lo que sugiere p茅rdida de informaci贸n.
- Conclusi贸n Final: El sobremuestreo result贸 ser la mejor t茅cnica para este caso, asegurando un mejor equilibrio entre precisi贸n y recall, sin perder efectividad en la clasificaci贸n.

##  Skills Obtenidas:
- Machine Learning: Random Forest, Decision Trees y Regresi贸n Log铆stica.
- Preprocesamiento de Datos: Manejo de valores nulos, codificaci贸n categ贸rica y normalizaci贸n.
- Balanceo de Clases: Uso de t茅cnicas de ajuste de pesos, sobremuestreo y submuestreo.
- M茅tricas de Evaluaci贸n: F1-score y AUC-ROC.
- Python: Extracci贸n y an谩lisis de datos.

##  Lecciones Aprendidas:
- La importancia de balancear las clases en datasets desbalanceados para evitar sesgos en el modelo.
- La m茅trica AUC-ROC es fundamental para evaluar modelos con clases desbalanceadas.
- La experimentaci贸n con diferentes t茅cnicas de balanceo permite identificar la m谩s efectiva seg煤n el contexto.
